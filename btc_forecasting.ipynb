{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "btc_forecasting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "19jVQv3fX4_AwBgaCy9Pb4t20A7U9N33F",
      "authorship_tag": "ABX9TyNrcCukQALWMZRiXIT4Nb3H"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DPybvqkNR0N"
      },
      "source": [
        "Loading dependency packages.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPamtUvP6sKu"
      },
      "source": [
        "import sys\r\n",
        "import os\r\n",
        "import os.path\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import datetime\r\n",
        "import random\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import preprocessing\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "from tensorflow.keras import initializers\r\n",
        "from tensorflow.keras import regularizers\r\n",
        "from tensorflow.keras.layers import *\r\n",
        "from tensorflow.keras.models import Model, Sequential\r\n",
        "from tensorflow.keras.models import model_from_json\r\n",
        "from tensorflow.keras.metrics import *\r\n",
        "\r\n",
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfDdKsQHf9v3"
      },
      "source": [
        "Superparameters for tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0mZVDXmgJ2l"
      },
      "source": [
        "# Features\r\n",
        "processing_from = '2020-10-01'\r\n",
        "processing_to = '2020-12-31'\r\n",
        "input_features = 2\r\n",
        "output_features = 1\r\n",
        "Tx = 24\r\n",
        "Ty = 1\r\n",
        "shift = 1\r\n",
        "cost_function=\"mae\"\r\n",
        "optimizer=\"adam\"\r\n",
        "BATCH_SIZE = 64\r\n",
        "learning_rate = 0.002\r\n",
        "num_epochs = 100\r\n",
        "L2_lambd = 0.0\r\n",
        "beta1 = 0.0\r\n",
        "beta2 = 0.0\r\n",
        "epsilon = 0.0\r\n",
        "LSTM_units = 128\r\n",
        "LSTM_dropout = 0.8\r\n",
        "dropout_rate = 0.8\r\n",
        "\r\n",
        "#INPUT_DATA\r\n",
        "IN_PATH = os.path.abspath('F:/Work/DATA/BTC/')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmHqopZ1UGXF"
      },
      "source": [
        "Define CSV reading function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUNtLKh5iDeS"
      },
      "source": [
        "# data reading\r\n",
        "def csv_reading(url, options):\r\n",
        "  if options == 0:\r\n",
        "    content = pd.read_csv(url)\r\n",
        "    return content\r\n",
        "  elif options == 1:\r\n",
        "    file_id = url.split('/')[-2]\r\n",
        "    path='https://drive.google.com/uc?export=download&id=' + file_id\r\n",
        "    file_name = 'bitstampUSD_1-min_data_2012-01-01_to_2020-12-31.csv'\r\n",
        "    auth.authenticate_user()\r\n",
        "    gauth = GoogleAuth()\r\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "    drive = GoogleDrive(gauth)\r\n",
        "    fileDownloaded = drive.CreateFile({'id':file_id})\r\n",
        "    fileDownloaded.GetContentFile(file_name)\r\n",
        "    content = pd.read_csv(file_name)\r\n",
        "    return content"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULBxDpppUawU"
      },
      "source": [
        "Loading dataset from Google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLTz7sR3UlgZ"
      },
      "source": [
        "dataset_url='https://drive.google.com/file/d/16AoK0vKAIshdyO96Td4Vfmnf_6cdTBko/view?usp=sharing'\r\n",
        "btc = csv_reading(dataset_url, 1)\r\n",
        "btc['Timestamp'] = pd.to_datetime(btc.Timestamp, unit='s')\r\n",
        "print(btc.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lht0w_bCHcHj"
      },
      "source": [
        "Visualization and preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1L1gjnhU2Z2"
      },
      "source": [
        "price = btc.resample('h', on='Timestamp')[['Weighted_Price']].mean()\r\n",
        "volume_usd = btc.resample('h', on='Timestamp')[['Volume_(Currency)']].sum()\r\n",
        "fig, axs = plt.subplots(2, 1, figsize=(20,10))\r\n",
        "fig.suptitle('Full BTC historical trading (hourly)', fontsize= 18, color='b')\r\n",
        "axs[0].plot(price, 'g')\r\n",
        "axs[0].set_ylabel('BTC price ($)')\r\n",
        "axs[1].plot(volume_usd, 'r')\r\n",
        "axs[1].set_ylabel('BTC volume (currency) ($)')\r\n",
        "#plt.setp(axs, xlim=[datetime.date(2017, 1, 26), datetime.date(2018, 2, 1)])\r\n",
        "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# removed NaN and slice data\r\n",
        "price.fillna(method ='bfill', inplace = True)\r\n",
        "volume_usd.fillna(method ='bfill', inplace = True)\r\n",
        "price = price[processing_from:processing_to]\r\n",
        "volume_usd = volume_usd[processing_from:processing_to]\r\n",
        "fig, axs = plt.subplots(2, 1, figsize=(20,10))\r\n",
        "fig.suptitle('Sliced BTC historical trading (hourly)', fontsize= 18, color='b')\r\n",
        "axs[0].plot(price, 'g')\r\n",
        "axs[0].set_ylabel('BTC price ($)')\r\n",
        "axs[1].plot(volume_usd, 'r')\r\n",
        "axs[1].set_ylabel('BTC volume (currency) ($)')\r\n",
        "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\r\n",
        "plt.show()\r\n",
        "btc = pd.concat([price, volume_usd], join = 'outer', axis = 1)\r\n",
        "print(btc.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhxMVZpumaxw"
      },
      "source": [
        "Define model Generator to create data for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfOhXNsgmp5_"
      },
      "source": [
        "def BTC_forecasting_model(num_of_input_features, Tx, num_of_out_features, Ty, LSTM_units, LSTM_dropout, dropout_rate):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(LSTM(LSTM_units, activation='relu', return_sequences=True, input_shape=(Tx, num_of_input_features), dropout=LSTM_dropout))\r\n",
        "  model.add(Dropout(rate=dropout_rate))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "  model.add(LSTM(LSTM_units, dropout=LSTM_dropout))\r\n",
        "  model.add(Dropout(rate=dropout_rate))\r\n",
        "  model.add(Dense(1, activation='sigmoid'))\r\n",
        "  \r\n",
        "  if optimizer == 'adam':\r\n",
        "    opt = optimizers.Adam(learning_rate=learning_rate)\r\n",
        "  elif optimizer == 'SGD':\r\n",
        "    opt = optimizers.SGD(learning_rate=learning_rate)\r\n",
        "  model.compile(optimizer=opt, loss=cost_function, metrics=[MeanSquaredError()])\r\n",
        "  return model\r\n",
        "\r\n",
        "class WindowGenerator():\r\n",
        "  def __init__(self, input_width, label_width, shift,\r\n",
        "               input_df,\r\n",
        "               label_columns=None):\r\n",
        "    # Store the raw data.\r\n",
        "    self.input_df = input_df\r\n",
        "\r\n",
        "    # Work out the label column indices.\r\n",
        "    self.label_columns = label_columns\r\n",
        "    if label_columns is not None:\r\n",
        "      self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\r\n",
        "    self.column_indices = {name: i for i, name in enumerate(input_df.columns)}\r\n",
        "\r\n",
        "    # Work out the window parameters.\r\n",
        "    self.input_width = input_width\r\n",
        "    self.label_width = label_width\r\n",
        "    self.shift = shift\r\n",
        "\r\n",
        "    self.total_window_size = input_width + shift\r\n",
        "\r\n",
        "    self.input_slice = slice(0, input_width)\r\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\r\n",
        "\r\n",
        "    self.label_start = self.total_window_size - self.label_width\r\n",
        "    self.labels_slice = slice(self.label_start, None)\r\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\r\n",
        "\r\n",
        "  def __repr__(self):\r\n",
        "    return '\\n'.join([\r\n",
        "        f'Total window size: {self.total_window_size}',\r\n",
        "        f'Input indices: {self.input_indices}',\r\n",
        "        f'Label indices: {self.label_indices}',\r\n",
        "        f'Label column name(s): {self.label_columns}'])\r\n",
        "  \r\n",
        "def sequence_data_generator(df, label_columns, input_len, output_len, shift, batch_size):\r\n",
        "  total_window_size = input_len + shift\r\n",
        "  inputs = np.array(df)\r\n",
        "  labels = np.array(df[label_columns])\r\n",
        "  x_shape = (batch_size, input_len, inputs.shape[1])\r\n",
        "  x_batch = np.zeros(shape=x_shape, dtype=np.float16)\r\n",
        "  y_shape = (batch_size, output_len, 1)\r\n",
        "  y_batch = np.zeros(shape=y_shape, dtype=np.float16)\r\n",
        "\r\n",
        "  while True:\r\n",
        "    for i in range(batch_size):\r\n",
        "      idx = np.random.randint(len(inputs) - total_window_size)\r\n",
        "      x_batch[i] = inputs[idx:idx+input_len]\r\n",
        "      y_batch[i] = labels[idx + total_window_size-output_len:idx + total_window_size]\r\n",
        "    yield (x_batch, y_batch)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA8z8W6dnOCj"
      },
      "source": [
        "Normalize data and split into train and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMs-GbcVLw1f"
      },
      "source": [
        "columns_name = btc.columns\r\n",
        "label_columns = [columns_name[0]]\r\n",
        "scaler = preprocessing.MinMaxScaler()\r\n",
        "btc_scaled = btc.copy()\r\n",
        "scaler = scaler.fit(btc)\r\n",
        "btc_scaled[columns_name] = scaler.transform(btc)\r\n",
        "print(btc_scaled.head())\r\n",
        "train, test = train_test_split(btc_scaled, test_size=0.2, random_state=1)\r\n",
        "train, validate = train_test_split(train, test_size=0.25, random_state=1)\r\n",
        "print('train size: ' + str(len(train)))\r\n",
        "print('validate size: ' + str(len(validate)))\r\n",
        "print('test size: ' + str(len(test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT0pcxxSWF3U"
      },
      "source": [
        "Model, train and validate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDfQrwYTri1w"
      },
      "source": [
        "model = BTC_forecasting_model(input_features, Tx, output_features, Ty, LSTM_units, LSTM_dropout, dropout_rate)\r\n",
        "model.summary()\r\n",
        "history = model.fit(sequence_data_generator(train, label_columns, Tx, Ty, shift, BATCH_SIZE),validation_data=sequence_data_generator(validate, label_columns, Tx, Ty, shift, BATCH_SIZE),validation_steps=len(validate)-Tx-shift, steps_per_epoch=len(train)-Tx-shift, epochs=num_epochs)\r\n",
        "\r\n",
        "plt.plot(history.history['loss'], label='Training Loss')\r\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "# predict on train/test dataset\r\n",
        "test_predictions = model.predict(sequence_data_generator(test, label_columns, Tx, Ty, shift, len(test) - shift - Tx), steps=1)\r\n",
        "test_real = np.array(test[['Weighted_Price']])[Tx+shift-Ty:,0]\r\n",
        "train_predictions = model.predict(sequence_data_generator(train, label_columns, Tx, Ty, shift, len(train) - shift - Tx), steps=1)\r\n",
        "train_real = np.array(train[['Weighted_Price']])[Tx+shift-Ty:,0]\r\n",
        "\r\n",
        "#inverse_scaler = preprocessing.MinMaxScaler()\r\n",
        "#inverse_scaler.min_,inverse_scaler.scale_ = scaler.min_[0],scaler.scale_[0]\r\n",
        "#predictions = inverse_scaler.inverse_transform(predictions)\r\n",
        "\r\n",
        "plt.figure(figsize=(20,10))\r\n",
        "plt.plot(test_predictions[0:100], 'ro', label='test predict')\r\n",
        "plt.plot(test_real[0:100], 'r-x', label='test actual')\r\n",
        "plt.plot(train_predictions[0:100], 'bo', label='Train predict')\r\n",
        "plt.plot(train_real[0:100], 'b-x', label='Train actual')\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b52d-Cwb4m9"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}